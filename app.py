"""
Chainlit UI å±¤
è² è²¬è™•ç†ç”¨æˆ¶ç•Œé¢äº¤äº’ï¼Œå°‡æ¥­å‹™é‚è¼¯å§”æ‰˜çµ¦æœå‹™å±¤
éµå®ˆå–®ä¸€è·è²¬åŸå‰‡ (Single Responsibility Principle)
"""
import chainlit as cl
from services import LLMService, ImageService


# é…ç½®åƒæ•¸
CONFIG = {
    "MODEL": "gemma3:4b",
    "BASE_URL": "http://localhost:11434",
    "TEMPERATURE": 0.7
}


@cl.on_chat_start
async def start():
    """åˆå§‹åŒ–èŠå¤©æœƒè©±"""
    # åˆå§‹åŒ–æœå‹™å±¤
    llm_service = LLMService(
        model=CONFIG["MODEL"],
        base_url=CONFIG["BASE_URL"],
        temperature=CONFIG["TEMPERATURE"]
    )
    
    # å°‡æœå‹™å­˜å„²åœ¨ç”¨æˆ¶æœƒè©±ä¸­
    cl.user_session.set("llm_service", llm_service)
    
    # ç²å–æ¨¡å‹ä¿¡æ¯
    model_info = llm_service.get_model_info()
    
    # æ­¡è¿è¨Šæ¯
    await cl.Message(
        content=f"ğŸ‘‹ æ­¡è¿ä½¿ç”¨ AI åŠ©æ‰‹ï¼\n\n"
                f"ğŸ“¦ ç•¶å‰æ¨¡å‹: **{model_info['model']}**\n\n"
                f"ğŸ’¬ æ‚¨å¯ä»¥ï¼š\n"
                f"- è¼¸å…¥æ–‡å­—é€²è¡Œå°è©±\n"
                f"- ğŸ“ é»æ“Šè¼¸å…¥æ¡†æ—çš„æŒ‰éˆ•ä¸Šå‚³åœ–ç‰‡\n"
                f"- ğŸ–±ï¸ æˆ–ç›´æ¥æ‹–æ‹‰åœ–ç‰‡åˆ°èŠå¤©å€åŸŸ",
    ).send()


@cl.on_message
async def handle_message(message: cl.Message):
    """
    è™•ç†ç”¨æˆ¶è¨Šæ¯
    UIå±¤åªè² è²¬æ¥æ”¶è¼¸å…¥ã€é¡¯ç¤ºè¼¸å‡ºï¼Œæ¥­å‹™é‚è¼¯å§”æ‰˜çµ¦æœå‹™å±¤
    """
    # ç²å–æœå‹™å±¤å¯¦ä¾‹
    llm_service = cl.user_session.get("llm_service")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡é™„ä»¶
    images = [file for file in message.elements if "image" in file.mime]
    
    try:
        if images:
            # è™•ç†åœ–ç‰‡è¨Šæ¯
            await _handle_image_message(message, images[0], llm_service)
        else:
            # è™•ç†ç´”æ–‡å­—è¨Šæ¯
            await _handle_text_message(message, llm_service)
            
    except Exception as e:
        await cl.Message(
            content=f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n\nè«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œä¸”æ¨¡å‹å·²ä¸‹è¼‰ã€‚"
        ).send()


async def _handle_text_message(message: cl.Message, llm_service: LLMService):
    """è™•ç†ç´”æ–‡å­—è¨Šæ¯"""
    # é¡¯ç¤ºè™•ç†ä¸­ç‹€æ…‹
    msg = cl.Message(content="")
    await msg.send()
    
    # å§”æ‰˜çµ¦æœå‹™å±¤è™•ç†æ¥­å‹™é‚è¼¯
    response_text = await cl.make_async(llm_service.process_text)(message.content)
    
    # æ›´æ–° UI
    msg.content = response_text
    await msg.update()


async def _handle_image_message(
    message: cl.Message, 
    image_file, 
    llm_service: LLMService
):
    """è™•ç†åœ–ç‰‡è¨Šæ¯"""
   
    msg = cl.Message(
        content="ğŸ” æ­£åœ¨åˆ†æåœ–ç‰‡...",
    )
    await msg.send()
    
    # ä½¿ç”¨æœå‹™å±¤è™•ç†åœ–ç‰‡
    image_data_url = ImageService.create_image_data_url(image_file.path)
    user_text = message.content or "è«‹æè¿°é€™å¼µåœ–ç‰‡"
    
    # å§”æ‰˜çµ¦æœå‹™å±¤è™•ç†æ¥­å‹™é‚è¼¯
    response_text = await cl.make_async(llm_service.process_image_with_text)(
        user_text, 
        image_data_url
    )
    
    # æ›´æ–° UIï¼ˆä¿ç•™åœ–ç‰‡é¡¯ç¤ºï¼‰
    msg.content = response_text
    await msg.update()


@cl.on_settings_update
async def setup_agent(settings):
    """è™•ç†è¨­ç½®æ›´æ–°"""
    print("è¨­ç½®å·²æ›´æ–°:", settings)
