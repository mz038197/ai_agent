import base64
import os
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage


def encode_image_to_base64(image_path):
    """å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64 æ ¼å¼"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


def create_image_message(prompt, image_path):
    """å‰µå»ºåŒ…å«åœ–ç‰‡å’Œæ–‡å­—çš„è¨Šæ¯"""
    image_data = encode_image_to_base64(image_path)
    
    return HumanMessage(
        content=[
            {"type": "text", "text": prompt},
            {
                "type": "image_url",
                "image_url": f"data:image/jpeg;base64,{image_data}"
            }
        ]
    )


def main():
    # é…ç½®åƒæ•¸
    BASE_URL = "http://localhost:11434"
    MODEL = "gemma3:4b"  # å¤šæ¨¡æ…‹æ¨¡å‹ï¼ˆæ”¯æ´æ–‡å­—å’Œåœ–ç‰‡ï¼‰
    TEMPERATURE = 0.7
    
    # åˆå§‹åŒ–å¤šæ¨¡æ…‹æ¨¡å‹
    chat = ChatOllama(
        model=MODEL,
        base_url=BASE_URL,
        temperature=TEMPERATURE,
    )
    
    print("âœ… æˆåŠŸé€£æ¥åˆ° Ollama LLM!")
    print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹: {MODEL}")
    print("=" * 50)
    print("\nä½¿ç”¨èªªæ˜:")
    print("- è¼¸å…¥æ–‡å­—é€²è¡Œå°è©±")
    print("- è¼¸å…¥ 'image:åœ–ç‰‡è·¯å¾‘ å•é¡Œ' ä¾†åˆ†æåœ–ç‰‡")
    print("  ä¾‹å¦‚: image:photo.jpg é€™å¼µåœ–ç‰‡è£¡æœ‰ä»€éº¼ï¼Ÿ")
    print("- è¼¸å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("=" * 50)
    
    try:
        while True:
            user_input = input("\nä½ : ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("æ‹œæ‹œï¼ä¸‹æ¬¡å†è¦‹!")
                break
            
            if not user_input:
                continue
            
            # æª¢æŸ¥æ˜¯å¦æ˜¯åœ–ç‰‡åˆ†æè«‹æ±‚
            if user_input.startswith("image:"):
                try:
                    # è§£æå‘½ä»¤: image:è·¯å¾‘ å•é¡Œ
                    parts = user_input[6:].strip().split(maxsplit=1)
                    
                    if len(parts) < 2:
                        print("âŒ æ ¼å¼éŒ¯èª¤ï¼è«‹ä½¿ç”¨: image:åœ–ç‰‡è·¯å¾‘ å•é¡Œ")
                        continue
                    
                    image_path = parts[0]
                    prompt = parts[1]
                    
                    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                    if not os.path.exists(image_path):
                        print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
                        continue
                    
                    print(f"ğŸ“· æ­£åœ¨åˆ†æåœ–ç‰‡: {image_path}")
                    print(f"â“ å•é¡Œ: {prompt}")
                    print("â³ è™•ç†ä¸­...")
                    
                    # ä½¿ç”¨å¤šæ¨¡æ…‹æ¨¡å‹è™•ç†åœ–ç‰‡
                    message = create_image_message(prompt, image_path)
                    response = chat.invoke([message])
                    
                    print(f"\næ¨¡å‹: {response.content}")
                    
                except FileNotFoundError:
                    print(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡: {image_path}")
                except Exception as e:
                    print(f"âŒ éŒ¯èª¤: {str(e)}")
                    print(f"\næç¤º: è«‹ç¢ºä¿æ¨¡å‹æ”¯æ´å¤šæ¨¡æ…‹åŠŸèƒ½")
                    print(f"å¯å˜—è©¦å…¶ä»–è¦–è¦ºæ¨¡å‹: ollama pull llava")
            else:
                # æ™®é€šæ–‡å­—å°è©±
                message = HumanMessage(content=user_input)
                response = chat.invoke([message])
                print(f"\næ¨¡å‹: {response.content}")
            
    except KeyboardInterrupt:
        print("\n\nç¨‹å¼å·²ä¸­æ–·")
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {str(e)}")
        print("\nè«‹ç¢ºä¿:")
        print("1. Ollama å·²å®‰è£ä¸¦é‹è¡Œ (ollama serve)")
        print(f"2. å·²ä¸‹è¼‰æ¨¡å‹ (ollama pull {MODEL})")
        print(f"3. Ollama æœå‹™é‹è¡Œåœ¨ {BASE_URL}")
        print(f"4. æ¨¡å‹æ”¯æ´å¤šæ¨¡æ…‹åŠŸèƒ½ï¼ˆæ–‡å­—+åœ–ç‰‡ï¼‰")


if __name__ == "__main__":
    main()
